from typing import Dict, Tuple

import cv2
import hydra
import numpy as np
import polars as pl
from loguru import logger
from omegaconf import DictConfig, OmegaConf

from src import utils
from src.datatypes import Detections

Color = Tuple[int, int, int]


def get_label_color(label) -> Color:
    # Generated by Claude 4 Opus
    hue = (label * 137) % 180
    color = cv2.cvtColor(
        np.array([[[hue, 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR
    )[0][0]
    return tuple(int(c) for c in color)


def draw_text(
    frame: cv2.Mat,
    text: str,
    x: int,
    y: int,
    background_color: Color,
    scale: float,
    thickness: int,
) -> None:

    (text_width, text_height), _ = cv2.getTextSize(
        text,
        cv2.FONT_HERSHEY_SIMPLEX,
        scale,
        thickness,
    )

    cv2.rectangle(
        frame,
        (x, y - text_height - 4),
        (x + text_width + 4, y),
        background_color,
        -1,
    )

    cv2.putText(
        frame,
        text,
        (x + 2, y - 2),
        cv2.FONT_HERSHEY_SIMPLEX,
        scale,
        (255, 255, 255),
        thickness,
        cv2.LINE_AA,
    )


def draw_white_area(frame: cv2.Mat, cfg: DictConfig) -> None:
    cv2.rectangle(
        frame,
        (cfg.x1, cfg.y1),
        (cfg.x2, cfg.y2),
        color=(255, 255, 255, 100),
        thickness=1,
    )


def load_detections_per_frame(path: str) -> Dict[int, pl.DataFrame]:
    return {
        group[0]: Detections.from_polars(grouped_df, round=True)
        for group, grouped_df in pl.read_parquet(path).group_by("frame")
    }


@hydra.main(config_path="config", config_name="viz", version_base=None)
def viz(cfg: DictConfig) -> None:
    logger.info(OmegaConf.to_yaml(cfg))

    label_names = pl.read_csv(cfg.labels, schema={"label": pl.Int32, "name": pl.String})
    label2name = {label: name for label, name in label_names.rows()}

    # Open video
    video_reader = utils.VideoReaderCV(cfg.video)
    video_writer = utils.VideoWriterCV(
        cfg.dst, fps=video_reader.fps, frame_size=video_reader.frame_size
    )

    # load detecions per frame
    frame2detections = load_detections_per_frame(cfg.detections)

    # load events
    if cfg.events is not None:
        events = utils.read_events(cfg.events)

    for idx, frame in video_reader:

        if cfg.display.white_area.enable:
            draw_white_area(frame, cfg.display.white_area)

        if idx in events:
            draw_text(frame, "event!", 50, 200, (0, 0, 0), 10, 5)

        if idx not in frame2detections:
            video_writer.write(frame)
            continue

        dets = frame2detections[idx]

        for i in range(len(dets)):

            x1 = dets.x1[i]
            y1 = dets.y1[i]
            x2 = dets.x2[i]
            y2 = dets.y2[i]
            score = dets.scores[i]
            label = dets.labels[i]

            color = get_label_color(dets.labels[i])

            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

            # Draw label
            if cfg.display.text.label or cfg.display.text.score:
                text = ""

                if cfg.display.text.label:
                    text += f"{label2name[label]} "
                if cfg.display.text.score:
                    text += f"{score:3f}"

                draw_text(
                    frame,
                    text,
                    x1,
                    y1,
                    background_color=color,
                    scale=cfg.display.text.scale,
                    thickness=cfg.display.text.thickness,
                )

        video_writer.write(frame)
    logger.info(f"Video saved to: {cfg.dst}")


if "__main__" == __name__:
    viz()
